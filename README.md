This repository contains research from my Data Science internship at Lawrence Livermore National Laboratory (LLNL). Our 5-person team investigated amodal segmentation for occluded object reconstruction using U-Net architectures, custom loss functions (Dice, Weighted BCE, Masked L1), and SAM2-based multimodal tracking. Also prototyped a diffusion-based generative model to enhance amodal completion in RGB images and videos. It was a collaborative effort as part of Team 6 in the LLNL Data Science Challenge 2025

## Repository Contents (Added):
- **SAM2 Vial Tracking.mp4** – Demo video showing SAM2-based multimodal segmentation for vial tracking and multi-object inference.
- **SAM2_LLNL_2025.ipynb** – Jupyter notebook for SAM2 experiments, including multimodal video segmentation pipelines and point-prompted inference.
- **Team 6_ DSC 25 Poster.pptx.pdf** – Poster summarizing the group’s findings, methods, and contributions during the internship. Presented to scientists, engineers, and technical staff.
  
## Credits:
This repository is based on group project work originally ([https://github.com/teammate1](https://github.com/rornelas2/2025DSC))  
I am maintaining this copy to showcase my contributions and portfolio.
